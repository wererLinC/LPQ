{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Example of using DeepSVDD for outlier detection\n",
    "\"\"\"\n",
    "# Author: Rafal Bodziony <bodziony.rafal@gmail.com>\n",
    "# License: BSD 2 clause\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# temporary solution for relative imports in case pyod is not installed\n",
    "# if pyod is installed, no need to use the following line\n",
    "sys.path.append(\n",
    "    os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), '..')))\n",
    "\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def main():\n",
    "    \n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    # 读取训练数据集\n",
    "    for i in range(5):\n",
    "        file = \"./dataSet/data_batch_%d\"%(i+1)\n",
    "        dicts = unpickle(file)\n",
    "        labels = dicts[b'labels']\n",
    "        data = dicts[b'data'].reshape(-1, 3, 32, 32) # 3*32x32\n",
    "        data = data.transpose(0,2,3,1)\n",
    "\n",
    "        for j in range(len(labels)):\n",
    "            img_data = data[j]\n",
    "            label = labels[j]\n",
    "            train_x.append(img_data)\n",
    "            train_y.append(label)\n",
    "    # 读取测试数据集\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    for i in range(1):\n",
    "        # file = \"./data_batch_%d\"%(i+1)\n",
    "        file = \"./dataSet/test_batch\"\n",
    "        dicts = unpickle(file)\n",
    "        labels = dicts[b'labels']\n",
    "        data = dicts[b'data'].reshape(-1, 3, 32, 32) # 3*32x32\n",
    "        data = data.transpose(0,2,3,1)\n",
    "\n",
    "        for j in range(len(labels)):\n",
    "            img_data = data[j]\n",
    "            label = labels[j]\n",
    "            test_x.append(img_data)\n",
    "            test_y.append(label)\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = np.array(train_y)\n",
    "    test_x = np.array(test_x)\n",
    "    test_y = np.array(test_y)\n",
    "    \n",
    "    contamination = 0.1  # percentage of outliers\n",
    "    use_ae = False # hyperparameter for use ae architecture instead of simple NN\n",
    "    random_state = 10 # if C is set to None use random_state\n",
    "    # Generate sample data\n",
    "    # Generate sample data\n",
    "    \n",
    "    nomal_label = 0\n",
    "    norm_train_x = train_x[train_y == nomal_label]\n",
    "    norm_train_x = norm_train_x.flatten()\n",
    "    norm_train_x = norm_train_x.reshape(-1, 3072)\n",
    "    \n",
    "    test_x = test_x.flatten()\n",
    "    test_x = test_x.reshape(-1, 3072)\n",
    "\n",
    "    \n",
    "    true_y = test_y.copy()\n",
    "    true_y[test_y == nomal_label] = 1\n",
    "    true_y[test_y != nomal_label] = 0\n",
    "\n",
    "    # train DeepSVDD detector (Without-AE)\n",
    "    clf_name = 'DeepSVDD'\n",
    "    clf = DeepSVDD(use_ae=use_ae, epochs=50, contamination=contamination,\n",
    "                   random_state=random_state)\n",
    "    clf.fit(norm_train_x)\n",
    "\n",
    "    # get the prediction labels and outlier scores of the training data\n",
    "    y_train_pred = clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "    y_train_scores = clf.decision_scores_  # raw outlier scores\n",
    "    for i in range(10):\n",
    "        start_time = time.time()\n",
    "        y_test_pred = clf.predict(test_x)  # outlier labels (0 or 1)\n",
    "        print(\"平均消耗的时间为\", ((time.time()-start_time) / test_x.shape[0]*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "net_output (Dense)           (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sub_1 (TensorFlo [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Pow_1 (TensorFlo [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlo [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Mean_1 (TensorFl [()]                      0         \n",
      "_________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorF [()]                      0         \n",
      "_________________________________________________________________\n",
      "add_loss_1 (AddLoss)         ()                        0         \n",
      "=================================================================\n",
      "Total params: 198,752\n",
      "Trainable params: 198,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 8.5140 - val_loss: 4.7398\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 4.5916 - val_loss: 4.1963\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 3.0889 - val_loss: 3.5219\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 2.8263 - val_loss: 2.1657\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 2.0224 - val_loss: 1.7975\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.5873 - val_loss: 1.6415\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.3616 - val_loss: 1.3807\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.1658 - val_loss: 1.2202\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 1.2001 - val_loss: 1.0834\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9470 - val_loss: 1.0044\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 0.8919 - val_loss: 0.9347\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8593 - val_loss: 0.8892\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8451 - val_loss: 0.8828\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8377 - val_loss: 0.8665\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.8219 - val_loss: 0.8630\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 0.8248 - val_loss: 0.9678\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8773 - val_loss: 0.9027\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9222 - val_loss: 1.0955\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9241 - val_loss: 0.9302\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8553 - val_loss: 0.8330\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8358 - val_loss: 0.8472\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8426 - val_loss: 0.8599\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8426 - val_loss: 0.8187\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8074 - val_loss: 0.8166\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8070 - val_loss: 0.8161\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8066 - val_loss: 0.8164\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8065 - val_loss: 0.8159\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8064 - val_loss: 0.8158\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8065 - val_loss: 0.8159\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8066 - val_loss: 0.8163\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8072 - val_loss: 0.8158\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8071 - val_loss: 0.8187\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8166 - val_loss: 0.8156\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8065 - val_loss: 0.8155\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8064 - val_loss: 0.8153\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8064 - val_loss: 0.8153\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8072 - val_loss: 0.8164\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.9791 - val_loss: 0.9164\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8538 - val_loss: 0.8326\n",
      "Epoch 40/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8098 - val_loss: 0.8139\n",
      "Epoch 41/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8068 - val_loss: 0.8136\n",
      "Epoch 42/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8065 - val_loss: 0.8134\n",
      "Epoch 43/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8064 - val_loss: 0.8134\n",
      "Epoch 44/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8064 - val_loss: 0.8134\n",
      "Epoch 45/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8064 - val_loss: 0.8134\n",
      "Epoch 46/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8064 - val_loss: 0.8134\n",
      "Epoch 47/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8064 - val_loss: 0.8134\n",
      "Epoch 48/50\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 0.8064 - val_loss: 0.8134\n",
      "Epoch 49/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8064 - val_loss: 0.8134\n",
      "Epoch 50/50\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 0.8064 - val_loss: 0.8134\n",
      "平均消耗的时间为 0.09901442527770997\n",
      "平均消耗的时间为 0.09416141510009765\n",
      "平均消耗的时间为 0.0980666160583496\n",
      "平均消耗的时间为 0.10419297218322754\n",
      "平均消耗的时间为 0.10626623630523681\n",
      "平均消耗的时间为 0.09536807537078858\n",
      "平均消耗的时间为 0.09386568069458007\n",
      "平均消耗的时间为 0.10570313930511474\n",
      "平均消耗的时间为 0.10397653579711914\n",
      "平均消耗的时间为 0.10901811122894288\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
